{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGP-ID-Bulletins.ipynb\n",
    "\n",
    "Shredder for: Singapore Communicable Diseases Agency (CDA) weekly infectious disease bulletin.\n",
    "\n",
    "Assumes downloaded pdf files from the targetted page (https://www.cda.gov.sg/resources/weekly-infectious-diseases-bulletin-2025) into a local directory (datadir). \n",
    "Reads the text from each local pdf file, extracting key fields. \n",
    "\n",
    "Writes the collected data out as an Excel file:\n",
    "- sheet: SARS-COV-2 - data relating to SARS-COV-2 / COVID-19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "import dateutil # pip install python-dateutil\n",
    "import pymupdf\n",
    "import os\n",
    "import pandas\n",
    "import re\n",
    "import time\n",
    "\n",
    "datadir = 'c:/dev/covid-19-world-vaccinations/SGP/'\n",
    "output_filename = datadir + \"SGP-ID-Bulletins.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_pdf(pdf_file):\n",
    "\n",
    "# open a pdf file, search for the key fields and return them\n",
    "    \n",
    "    with pymupdf.open(pdf_file) as doc:  # open document\n",
    "        text = chr(12).join([page.get_text() for page in doc])\n",
    "\n",
    "        e_week = 0\n",
    "        e_week_dates = ''\n",
    "        e_week_end_date = ''\n",
    "        ARI_average_daily = 0\n",
    "        Adult_SARS_CoV_2_pct = 0\n",
    "        Paediatric_SARS_CoV_2_pct = 0\n",
    "        ARI_samples_week = 0\n",
    "        ARI_samples_COVID_19_pct = 0\n",
    "\n",
    "        # search for: ARI indicators for E-week NNN (DATES)\n",
    "        pattern = r'ARI\\s+indicators\\s+for\\s+E-week\\s*(\\d+(?:,\\d+)?)\\s*\\((.*?)\\)'\n",
    "        match = re.search(pattern, text, re.DOTALL)\n",
    "        if match:\n",
    "            # assign results\n",
    "            e_week = int(match.group(1))\n",
    "            e_week_dates = match.group(2) \n",
    "            e_week_end_date = e_week_dates.split('-')[1].strip()\n",
    "\n",
    "        # search for: polyclinics for ARI was NNN\n",
    "        pattern = r\"polyclinics\\s+for\\s+ARI\\s+was\\s+(\\d+(?:,\\d+)?)\\s+\"\n",
    "        match = re.search(pattern, text, re.DOTALL)\n",
    "        if match:\n",
    "            # assign result\n",
    "            ARI_average_daily = int(match.group(1))\n",
    "\n",
    "        # search for: Adult samples ... SARS-COV-2 (NNN\n",
    "        pattern = r\"Adult\\s+samples.*SARS-CoV-2\\s+\\((\\d+(?:,\\d+)?)\"\n",
    "        match = re.search(pattern, text, re.DOTALL)\n",
    "        if match:\n",
    "            # assign result\n",
    "            Adult_SARS_CoV_2_pct = int(match.group(1))\n",
    "\n",
    "        # search for: Paediatric samples ... SARS-COV-2 (NNN\n",
    "        pattern = r\"Paediatric\\s+samples.*SARS-CoV-2\\s+\\((\\d+(?:,\\d+)?)\"\n",
    "        match = re.search(pattern, text, re.DOTALL)\n",
    "        if match:\n",
    "            # assign result\n",
    "            Paediatric_SARS_CoV_2_pct = int(match.group(1))\n",
    "\n",
    "        # search for:  COVID-19 among ARI samples (n= NNN) in the community was NNN\n",
    "        pattern = r\"COVID-19\\s+among\\s+ARI\\s+samples\\s+\\(n=\\s+(\\d+(?:,\\d+)?).*in\\s+the\\s+community\\s+was\\s+(\\d+(?:,\\d+)?)\"\n",
    "        match = re.search(pattern, text, re.DOTALL)\n",
    "        if match:\n",
    "            # assign result\n",
    "            ARI_samples_week = int(match.group(1))\n",
    "            ARI_samples_COVID_19_pct = int(match.group(2))\n",
    "\n",
    "\n",
    "        return e_week , e_week_dates , e_week_end_date, ARI_average_daily , Adult_SARS_CoV_2_pct , Paediatric_SARS_CoV_2_pct , ARI_samples_week , ARI_samples_COVID_19_pct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process local files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'trim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      8\u001b[0m     pdf_file \u001b[38;5;241m=\u001b[39m datadir \u001b[38;5;241m+\u001b[39m filename\n\u001b[1;32m----> 9\u001b[0m     e_week , e_week_dates , e_week_end_date, ARI_average_daily , Adult_SARS_CoV_2_pct , Paediatric_SARS_CoV_2_pct , ARI_samples_week , ARI_samples_COVID_19_pct  \u001b[38;5;241m=\u001b[39m \u001b[43mextract_data_from_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# construct the output row and add it to the dataframe\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     output_row \u001b[38;5;241m=\u001b[39m [filename, e_week , e_week_dates , e_week_end_date, ARI_average_daily , Adult_SARS_CoV_2_pct , Paediatric_SARS_CoV_2_pct , ARI_samples_week , ARI_samples_COVID_19_pct]\n",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m, in \u001b[0;36mextract_data_from_pdf\u001b[1;34m(pdf_file)\u001b[0m\n\u001b[0;32m     22\u001b[0m     e_week \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     23\u001b[0m     e_week_dates \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m2\u001b[39m) \n\u001b[1;32m---> 24\u001b[0m     e_week_end_date \u001b[38;5;241m=\u001b[39m \u001b[43me_week_dates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrim\u001b[49m()\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# search for: polyclinics for ARI was NNN\u001b[39;00m\n\u001b[0;32m     27\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolyclinics\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+for\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+ARI\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+was\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+(?:,\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)?)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'trim'"
     ]
    }
   ],
   "source": [
    "output_data_df = pandas.DataFrame(columns=['source_file_name', 'e_week', 'e_week_dates', 'e_week_end_date', 'ARI_average_daily', 'Adult_SARS_CoV_2_pct', 'Paediatric_SARS_CoV_2_pct', 'ARI_samples_week', 'ARI_samples_COVID_19_pct'])\n",
    "  \n",
    "for file in os.listdir(datadir):\n",
    "    filename = os.fsdecode(file)\n",
    "    \n",
    "    # browse through all the local pdf files, gathering the search results into a dataframe for output\n",
    "    if filename.endswith('.pdf'):\n",
    "        pdf_file = datadir + filename\n",
    "        e_week , e_week_dates , e_week_end_date, ARI_average_daily , Adult_SARS_CoV_2_pct , Paediatric_SARS_CoV_2_pct , ARI_samples_week , ARI_samples_COVID_19_pct  = extract_data_from_pdf(pdf_file)\n",
    "\n",
    "\n",
    "        # construct the output row and add it to the dataframe\n",
    "        output_row = [filename, e_week , e_week_dates , e_week_end_date, ARI_average_daily , Adult_SARS_CoV_2_pct , Paediatric_SARS_CoV_2_pct , ARI_samples_week , ARI_samples_COVID_19_pct]\n",
    "        output_data_df.loc[len(output_data_df.index)] = output_row\n",
    "\n",
    "# sort df by e_week\n",
    "output_data_df = output_data_df.sort_values(['e_week']).reset_index(drop=True)\n",
    "\n",
    "output_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gather result dataframes and write out to Excel sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# write the output_data_df to an Excel file with Sheet name\n",
    "\n",
    "writer = pandas.ExcelWriter(output_filename, engine='xlsxwriter')\n",
    "my_sheet_name = \"SGP-ID-Bulletins\"\n",
    "output_data_df.to_excel(writer, sheet_name = my_sheet_name)\n",
    "writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
